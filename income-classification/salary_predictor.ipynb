{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67afae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "223c644a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.read_csv('income_evaluation.csv')\n",
    "display(df.shape)\n",
    "# Droping duplicates\n",
    "df=df.drop_duplicates()\n",
    "df[df.duplicated()]\n",
    "df.head(3)\n",
    "#Removing leading/trailing space and replacing in between space with under score.\n",
    "df.columns = (df.columns.str.strip().str.lower())\n",
    "\n",
    "# Replace '?' with mode in workclass and native-country\n",
    "col='workclass'\n",
    "mode_value = df[col].mode()[0]\n",
    "df[col] = df[col].replace(' ?', mode_value)\n",
    "\n",
    "col='native-country'\n",
    "mode_value = df[col].mode()[0]\n",
    "df[col] = df[col].replace(' ?', mode_value)\n",
    "\n",
    "col='income'\n",
    "#mode_value = df[col].mode()[0]\n",
    "df[col] = df[col].replace(' >50K', 1)\n",
    "df[col] = df[col].replace(' <=50K', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d8a3745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('relationship', 'sex', 0.6491087979307012)\n",
      "('marital-status', 'relationship', 0.4879663976816214)\n",
      "('marital-status', 'sex', 0.461807182455745)\n",
      "('relationship', 'income', 0.45351579634155065)\n",
      "('marital-status', 'income', 0.447314337676062)\n",
      "('occupation', 'sex', 0.4241770389935278)\n",
      "('race', 'native-country', 0.40543522435177093)\n",
      "('education', 'income', 0.3689222912649586)\n",
      "('occupation', 'income', 0.3519451962095364)\n",
      "('sex', 'income', 0.2158927904925206)\n",
      "('workclass', 'occupation', 0.20747803400515535)\n",
      "('education', 'occupation', 0.1870702466250539)\n",
      "('occupation', 'relationship', 0.1786183604154298)\n",
      "('workclass', 'income', 0.16836781914218513)\n",
      "('workclass', 'sex', 0.14308616538598945)\n",
      "('marital-status', 'occupation', 0.1331805085605658)\n",
      "('education', 'native-country', 0.13071014925696528)\n",
      "('education', 'relationship', 0.12258989249983518)\n",
      "('race', 'sex', 0.11837905460780355)\n",
      "('workclass', 'education', 0.10179590268913362)\n",
      "('race', 'income', 0.1008528343491578)\n",
      "('native-country', 'income', 0.09845162311378534)\n",
      "('relationship', 'race', 0.09813157345742837)\n",
      "('education', 'sex', 0.09564995627196757)\n",
      "('education', 'marital-status', 0.09164831984169187)\n",
      "('workclass', 'relationship', 0.0905332783986524)\n",
      "('relationship', 'native-country', 0.08460047318386103)\n",
      "('marital-status', 'race', 0.08421701579603003)\n",
      "('occupation', 'race', 0.08084396250510469)\n",
      "('workclass', 'marital-status', 0.07729280443509175)\n",
      "('education', 'race', 0.0750009286584347)\n",
      "('marital-status', 'native-country', 0.07130678309786048)\n",
      "('occupation', 'native-country', 0.07053252300167644)\n",
      "('sex', 'native-country', 0.06559616255973102)\n",
      "('workclass', 'race', 0.05511672776700514)\n",
      "('workclass', 'native-country', 0.044448396022802115)\n"
     ]
    }
   ],
   "source": [
    "# Categorical to categorical variables relationship.\n",
    "from scipy.stats import chi2_contingency\n",
    "# Chi-square for cat-to-cat column relationship\n",
    "def find_categorical_columns_relation(df, col1, col2):\n",
    "    confusion_matrix=pd.crosstab(df[col1], df[col2])\n",
    "    chi2, p, dof, expected = chi2_contingency(confusion_matrix)\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    min_dim = min(confusion_matrix.shape) - 1\n",
    "    cramers_v = np.sqrt(chi2 / (n * min_dim))\n",
    "    #print('col1:', col1, ',col2:', col2, ',Cramers V:', cramers_v)\n",
    "    return cramers_v # 0 means no relation and 1 means strong relation. It does not show direction of relation (positive or negative)\n",
    "    \n",
    "categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country','income']\n",
    "#find_categorical_columns_relation(df,'workclass','income')\n",
    "def already_computed(col1, col2):\n",
    "    if (col1, col2) in computed or (col2, col1) in computed:\n",
    "        return False\n",
    "    else:\n",
    "        computed.add((col1, col2))\n",
    "        return True\n",
    "lst=[]\n",
    "computed=set()\n",
    "for cat_col1 in categorical_features:\n",
    "    for cat_col2 in categorical_features:\n",
    "        if cat_col1 != cat_col2 and already_computed(cat_col1, cat_col2):\n",
    "            cramers_v=find_categorical_columns_relation(df, cat_col1, cat_col2)\n",
    "            lst.append((cat_col1, cat_col2, cramers_v))\n",
    "sorted_lst=sorted(lst, key=lambda x: x[2], reverse=True)\n",
    "for item in sorted_lst:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fad274f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('education', 'education-num', 1.000000000000129)\n",
      "('marital-status', 'age', 0.3290184100935994)\n",
      "('occupation', 'education-num', 0.30968754778974134)\n",
      "('relationship', 'age', 0.22487032262909384)\n",
      "('income', 'education-num', 0.11240698692569837)\n",
      "('occupation', 'hours-per-week', 0.09705707162893941)\n",
      "('relationship', 'hours-per-week', 0.09599269895157475)\n",
      "('native-country', 'education-num', 0.0757959202457202)\n",
      "('marital-status', 'hours-per-week', 0.06277137535617197)\n",
      "('income', 'age', 0.054773361669666995)\n",
      "('income', 'hours-per-week', 0.052742843648214396)\n",
      "('education', 'age', 0.05267952052142049)\n",
      "('sex', 'hours-per-week', 0.05252673379035869)\n",
      "('income', 'capital-gain', 0.04987919175002811)\n",
      "('workclass', 'age', 0.04279804280575228)\n",
      "('education', 'capital-gain', 0.03914931537864205)\n",
      "('education', 'hours-per-week', 0.03771232059562653)\n",
      "('workclass', 'education-num', 0.03590072571671229)\n",
      "('occupation', 'age', 0.034904011458088066)\n",
      "('workclass', 'hours-per-week', 0.02822623957581907)\n",
      "('relationship', 'education-num', 0.02602491045042059)\n",
      "('native-country', 'fnlwgt', 0.02502672887632047)\n",
      "('income', 'capital-loss', 0.02265048037636839)\n",
      "('race', 'fnlwgt', 0.019748795950995105)\n",
      "('occupation', 'capital-gain', 0.014302742027852927)\n",
      "('marital-status', 'education-num', 0.013353968844481352)\n",
      "('race', 'education-num', 0.01206182304482279)\n",
      "('workclass', 'capital-gain', 0.010791800498997136)\n",
      "('education', 'capital-loss', 0.00983634995524718)\n",
      "('relationship', 'capital-gain', 0.008174883176616948)\n",
      "('sex', 'age', 0.007869164632840348)\n",
      "('native-country', 'age', 0.007722450497382596)\n",
      "('relationship', 'capital-loss', 0.007690074990880836)\n",
      "('marital-status', 'capital-gain', 0.007601724946771943)\n",
      "('occupation', 'capital-loss', 0.007242590660408222)\n",
      "('marital-status', 'capital-loss', 0.006670109783447074)\n",
      "('education', 'fnlwgt', 0.004506593522944591)\n",
      "('occupation', 'fnlwgt', 0.003072189949766911)\n",
      "('race', 'hours-per-week', 0.002992629482538757)\n",
      "('marital-status', 'fnlwgt', 0.0029517664888350694)\n",
      "('native-country', 'capital-loss', 0.0027441280048542127)\n",
      "('workclass', 'fnlwgt', 0.0026746398739326102)\n",
      "('sex', 'capital-gain', 0.002351182769740176)\n",
      "('native-country', 'hours-per-week', 0.0022354100541043804)\n",
      "('workclass', 'capital-loss', 0.0020824785050731856)\n",
      "('sex', 'capital-loss', 0.002076721646432645)\n",
      "('race', 'age', 0.0019189674291736336)\n",
      "('relationship', 'fnlwgt', 0.0013811101569229545)\n",
      "('native-country', 'capital-gain', 0.0011016827667742059)\n",
      "('sex', 'fnlwgt', 0.0007338372146478413)\n",
      "('race', 'capital-loss', 0.0007146851412662148)\n",
      "('race', 'capital-gain', 0.0005488868258837627)\n",
      "('sex', 'education-num', 0.00014897371043598136)\n",
      "('income', 'fnlwgt', 9.029464222715809e-05)\n"
     ]
    }
   ],
   "source": [
    "# Numerical columns correlation with categorical columns\n",
    "def correlation_ratio(df, cat_col, num_col):\n",
    "    categories = np.array(df[cat_col])\n",
    "    values = np.array(df[num_col])\n",
    "\n",
    "    cat_means = [\n",
    "        values[categories == cat].mean()\n",
    "        for cat in np.unique(categories)\n",
    "    ]\n",
    "\n",
    "    grand_mean = values.mean()\n",
    "    numerator = sum(\n",
    "        len(values[categories == cat]) * (mean - grand_mean) ** 2\n",
    "        for cat, mean in zip(np.unique(categories), cat_means)\n",
    "    )\n",
    "    denominator = sum((values - grand_mean) ** 2)\n",
    "\n",
    "    return numerator / denominator # 0 means no relation and 1 means strong relation. It does not show direction of relation (positive or negative\n",
    "\n",
    "# eta_sq = correlation_ratio(df,'education', 'education-num')\n",
    "# print(eta_sq)\n",
    "categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country','income']\n",
    "numerical_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "lst=[]\n",
    "for cat_col in categorical_features:\n",
    "    for num_col in numerical_features:\n",
    "        eta_sq=correlation_ratio(df, cat_col, num_col)\n",
    "        lst.append((cat_col, num_col, eta_sq))\n",
    "\n",
    "sorted_lst=sorted(lst, key=lambda x: x[2], reverse=True)\n",
    "for item in sorted_lst:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5b71471",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['age','fnlwgt','capital-gain','capital-loss','hours-per-week']\n",
    "\n",
    "\n",
    "def list_outliers_quantile(df, col, lower_quantile, upper_quantile):\n",
    "    #display('col=',col)\n",
    "    lower = df[col].quantile(lower_quantile)\n",
    "    upper = df[col].quantile(upper_quantile)\n",
    "    df_outliers=df[(df[col]<lower) | (df[col]>upper)]\n",
    "    outlier_count=df_outliers.shape[0]\n",
    "    total_count=df.shape[0]\n",
    "    ratio=outlier_count/total_count\n",
    "    #print('lower_quantile=',lower,' upper_quantile=',upper,'df_outliers.count_quantile=',outlier_count,'total records_quantile=',total_count,' ratio_quantile=',ratio)\n",
    "    #display(df_outliers)\n",
    "    df[col] = df[col].clip(lower, upper)\n",
    "\n",
    "for col in ['age','fnlwgt','capital-gain','capital-loss','hours-per-week']:\n",
    "    list_outliers_quantile(df,col,.01,.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ae8021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPlitting into X and Y\n",
    "# education is highly correlated with education-num\n",
    "X=df.drop(columns=['income','education'], axis=1)\n",
    "\n",
    "Y=df['income']\n",
    "str_cat_cols=['workclass','marital-status','occupation','relationship', 'race', 'sex', 'native-country']\n",
    "num_cat_cols=['education-num']\n",
    "pure_num_cols=['fnlwgt','capital-gain', 'capital-loss','age','hours-per-week']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec0e82b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>const</td>\n",
       "      <td>24.122326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capital-gain</td>\n",
       "      <td>1.030405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age</td>\n",
       "      <td>1.029572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hours-per-week</td>\n",
       "      <td>1.018965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capital-loss</td>\n",
       "      <td>1.010252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fnlwgt</td>\n",
       "      <td>1.006324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Features        VIF\n",
       "0           const  24.122326\n",
       "2    capital-gain   1.030405\n",
       "4             age   1.029572\n",
       "5  hours-per-week   1.018965\n",
       "3    capital-loss   1.010252\n",
       "1          fnlwgt   1.006324"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate vif. Features are not highly correlated.\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "X_numeric=X[pure_num_cols]\n",
    "X_intercept = add_constant(X_numeric)\n",
    "\n",
    "vif_df=pd.DataFrame()\n",
    "vif_df['Features']=X_intercept.columns\n",
    "\n",
    "vif_df['VIF'] = [\n",
    "    variance_inflation_factor(X_intercept.values, i)\n",
    "    for i in range(X_intercept.shape[1])\n",
    "]\n",
    "display(vif_df.sort_values(by='VIF', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "587a1077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=7, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c98375fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature encoding categorical columns\n",
    "from category_encoders import TargetEncoder\n",
    "te = TargetEncoder(cols=str_cat_cols,smoothing=10)\n",
    "\n",
    "te.fit(X_train, pd.Series(Y_train))\n",
    "X_train=te.transform(X_train)\n",
    "X_test=te.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6bb0eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fnlwgt            0.799468\n",
       "capital-gain      4.569087\n",
       "capital-loss      4.406497\n",
       "age               0.481958\n",
       "hours-per-week    0.011491\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find skewness:\n",
    "skewness = df[pure_num_cols].skew()\n",
    "skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1347315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8860</th>\n",
       "      <td>56</td>\n",
       "      <td>0.209911</td>\n",
       "      <td>95763.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.104326</td>\n",
       "      <td>0.227617</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.255895</td>\n",
       "      <td>0.305445</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.246697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15982</th>\n",
       "      <td>44</td>\n",
       "      <td>0.209911</td>\n",
       "      <td>205706.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.047426</td>\n",
       "      <td>0.484518</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.255895</td>\n",
       "      <td>0.109824</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.246697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15753</th>\n",
       "      <td>38</td>\n",
       "      <td>0.209911</td>\n",
       "      <td>103323.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.444772</td>\n",
       "      <td>0.484518</td>\n",
       "      <td>0.447065</td>\n",
       "      <td>0.255895</td>\n",
       "      <td>0.305445</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.246697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass    fnlwgt  education-num  marital-status  occupation  \\\n",
       "8860    56   0.209911   95763.0              6        0.104326    0.227617   \n",
       "15982   44   0.209911  205706.0              9        0.047426    0.484518   \n",
       "15753   38   0.209911  103323.0              9        0.444772    0.484518   \n",
       "\n",
       "       relationship      race       sex  capital-gain  capital-loss  \\\n",
       "8860       0.105200  0.255895  0.305445          -0.0          -0.0   \n",
       "15982      0.105200  0.255895  0.109824          -0.0          -0.0   \n",
       "15753      0.447065  0.255895  0.305445          -0.0          -0.0   \n",
       "\n",
       "       hours-per-week  native-country  \n",
       "8860               45        0.246697  \n",
       "15982              40        0.246697  \n",
       "15753              40        0.246697  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treating skewness\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "cols=[\"capital-gain\", \"capital-loss\"]\n",
    "\n",
    "pt.fit(X_train[cols])\n",
    "X_train[cols]=pt.transform(X_train[cols])\n",
    "X_test[cols]=pt.transform(X_test[cols])\n",
    "X_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18bd88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train[pure_num_cols])\n",
    "\n",
    "def scale(input_df,cols):\n",
    "    tmp_df=pd.DataFrame(scaler.transform(input_df[cols]), columns=cols, index=input_df.index)\n",
    "    input_df[cols]=tmp_df[cols]\n",
    "    return tmp_df\n",
    "\n",
    "X_train[pure_num_cols]=scale(X_train, pure_num_cols)\n",
    "X_test[pure_num_cols]=scale(X_test, pure_num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e60ff6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating class impbalance by increasing minority class number using smotetomek method\n",
    "from imblearn.combine import SMOTETomek\n",
    "smt = SMOTETomek(random_state=7)\n",
    "X_train, Y_train = smt.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5f7bffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "0    16851\n",
       "1    16851\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f0f494b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best Parameters:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'max_depth': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Best CV Score:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.15171016900432582"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: test 0.8137676705593117\n",
      "\n",
      "Confusion Matrix:test\n",
      " [[6305 1105]\n",
      " [ 713 1639]]\n",
      "\n",
      "Classification Report:test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87      7410\n",
      "           1       0.60      0.70      0.64      2352\n",
      "\n",
      "    accuracy                           0.81      9762\n",
      "   macro avg       0.75      0.77      0.76      9762\n",
      "weighted avg       0.83      0.81      0.82      9762\n",
      "\n",
      "Accuracy:train 0.85137380570886\n",
      "\n",
      "Confusion Matrix:train\n",
      " [[14391  2460]\n",
      " [ 2549 14302]]\n",
      "\n",
      "Classification Report:train\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     16851\n",
      "           1       0.85      0.85      0.85     16851\n",
      "\n",
      "    accuracy                           0.85     33702\n",
      "   macro avg       0.85      0.85      0.85     33702\n",
      "weighted avg       0.85      0.85      0.85     33702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "#Decision Tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'ccp_alpha': [0.0, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                        \n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=3)\n",
    "\n",
    "# X_train=X_train[['workclass','marital-status','occupation','relationship', 'race', 'sex', 'native-country',\n",
    "#      'fnlwgt','capital-gain', 'capital-loss','age','education-num']] #Reorder columns so that it is easy to pass columns in correct order in streamlit.\n",
    "# X_test=X_test[['workclass','marital-status','occupation','relationship', 'race', 'sex', 'native-country',\n",
    "#      'fnlwgt','capital-gain', 'capital-loss','age','education-num']] #Reorder columns so that it is easy to pass columns in correct order in streamlit.\n",
    "\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "display(\"Best Parameters:\", grid_search.best_params_)\n",
    "display(\"Best CV Score:\", grid_search.best_score_)\n",
    "\n",
    "best_dt = grid_search.best_estimator_\n",
    "Y_pred = best_dt.predict(X_test)\n",
    "print(\"Accuracy: test\", accuracy_score(Y_test, Y_pred))\n",
    "print(\"\\nConfusion Matrix:test\\n\", confusion_matrix(Y_test, Y_pred))\n",
    "print(\"\\nClassification Report:test\\n\", classification_report(Y_test, Y_pred))\n",
    "\n",
    "Y_pred = best_dt.predict(X_train)\n",
    "print(\"Accuracy:train\", accuracy_score(Y_train, Y_pred))\n",
    "print(\"\\nConfusion Matrix:train\\n\", confusion_matrix(Y_train, Y_pred))\n",
    "print(\"\\nClassification Report:train\\n\", classification_report(Y_train, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a89a0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['power_transformer_skewness_handler.pkl']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(dt, 'dt_classifier_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(te, 'target_encoder.pkl')\n",
    "joblib.dump(pt, 'power_transformer_skewness_handler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5346b495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best CV Score: 0.6160608682716167\n",
      "Accuracy: test 0.847060028682647\n",
      "\n",
      "Confusion Matrix:test\n",
      " [[6720  690]\n",
      " [ 803 1549]]\n",
      "\n",
      "Classification Report:test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      7410\n",
      "           1       0.69      0.66      0.67      2352\n",
      "\n",
      "    accuracy                           0.85      9762\n",
      "   macro avg       0.79      0.78      0.79      9762\n",
      "weighted avg       0.84      0.85      0.85      9762\n",
      "\n",
      "Accuracy:train 1.0\n",
      "\n",
      "Confusion Matrix:train\n",
      " [[16851     0]\n",
      " [    0 16851]]\n",
      "\n",
      "Classification Report:train\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16851\n",
      "           1       1.00      1.00      1.00     16851\n",
      "\n",
      "    accuracy                           1.00     33702\n",
      "   macro avg       1.00      1.00      1.00     33702\n",
      "weighted avg       1.00      1.00      1.00     33702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=2) \n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}  \n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=3\n",
    ") \n",
    "grid_search.fit(X_train, Y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Score:\", grid_search.best_score_)\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "Y_pred=best_rf.predict(X_test)\n",
    "print(\"Accuracy: test\", accuracy_score(Y_test, Y_pred))\n",
    "print(\"\\nConfusion Matrix:test\\n\", confusion_matrix(Y_test, Y_pred))\n",
    "print(\"\\nClassification Report:test\\n\", classification_report(Y_test, Y_pred))\n",
    "\n",
    "Y_pred=best_rf.predict(X_train)\n",
    "print(\"Accuracy:train\", accuracy_score(Y_train, Y_pred))\n",
    "print(\"\\nConfusion Matrix:train\\n\", confusion_matrix(Y_train, Y_pred))\n",
    "print(\"\\nClassification Report:train\\n\", classification_report(Y_train, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8d721b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: test 0.8329235812333539\n",
      "\n",
      "Confusion Matrix:test\n",
      " [[6319 1091]\n",
      " [ 540 1812]]\n",
      "\n",
      "Classification Report:test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.89      7410\n",
      "           1       0.62      0.77      0.69      2352\n",
      "\n",
      "    accuracy                           0.83      9762\n",
      "   macro avg       0.77      0.81      0.79      9762\n",
      "weighted avg       0.85      0.83      0.84      9762\n",
      "\n",
      "Accuracy:train 0.8916681502581449\n",
      "\n",
      "Confusion Matrix:train\n",
      " [[14621  2230]\n",
      " [ 1421 15430]]\n",
      "\n",
      "Classification Report:train\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89     16851\n",
      "           1       0.87      0.92      0.89     16851\n",
      "\n",
      "    accuracy                           0.89     33702\n",
      "   macro avg       0.89      0.89      0.89     33702\n",
      "weighted avg       0.89      0.89      0.89     33702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "xgbclassifier=XGBClassifier(n_estimators=100, max_depth=3,learning_rate=0.1)\n",
    "xgbclassifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred=xgbclassifier.predict(X_test)\n",
    "print(\"Accuracy: test\", accuracy_score(Y_test, Y_pred))\n",
    "print(\"\\nConfusion Matrix:test\\n\", confusion_matrix(Y_test, Y_pred))\n",
    "print(\"\\nClassification Report:test\\n\", classification_report(Y_test, Y_pred))\n",
    "\n",
    "Y_pred=xgbclassifier.predict(X_train)\n",
    "print(\"Accuracy:train\", accuracy_score(Y_train, Y_pred))\n",
    "print(\"\\nConfusion Matrix:train\\n\", confusion_matrix(Y_train, Y_pred))\n",
    "print(\"\\nClassification Report:train\\n\", classification_report(Y_train, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bfae41da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8849094\tbest: 0.8849094 (0)\ttotal: 14.4ms\tremaining: 4.31s\n",
      "50:\ttest: 0.9110222\tbest: 0.9110222 (50)\ttotal: 497ms\tremaining: 2.43s\n",
      "100:\ttest: 0.9151514\tbest: 0.9151514 (100)\ttotal: 1.01s\tremaining: 1.99s\n",
      "150:\ttest: 0.9160338\tbest: 0.9160338 (150)\ttotal: 1.49s\tremaining: 1.47s\n",
      "200:\ttest: 0.9172147\tbest: 0.9172235 (194)\ttotal: 2.13s\tremaining: 1.05s\n",
      "250:\ttest: 0.9175506\tbest: 0.9176583 (235)\ttotal: 2.72s\tremaining: 530ms\n",
      "299:\ttest: 0.9178206\tbest: 0.9179634 (288)\ttotal: 3.26s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9179634354\n",
      "bestIteration = 288\n",
      "\n",
      "Shrink model to first 289 iterations.\n",
      "Accuracy: test 0.8329235812333539\n",
      "\n",
      "Confusion Matrix:test\n",
      " [[6319 1091]\n",
      " [ 540 1812]]\n",
      "\n",
      "Classification Report:test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.89      7410\n",
      "           1       0.62      0.77      0.69      2352\n",
      "\n",
      "    accuracy                           0.83      9762\n",
      "   macro avg       0.77      0.81      0.79      9762\n",
      "weighted avg       0.85      0.83      0.84      9762\n",
      "\n",
      "Accuracy:train 0.8916681502581449\n",
      "\n",
      "Confusion Matrix:train\n",
      " [[14621  2230]\n",
      " [ 1421 15430]]\n",
      "\n",
      "Classification Report:train\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89     16851\n",
      "           1       0.87      0.92      0.89     16851\n",
      "\n",
      "    accuracy                           0.89     33702\n",
      "   macro avg       0.89      0.89      0.89     33702\n",
      "weighted avg       0.89      0.89      0.89     33702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    verbose=50,\n",
    "    random_seed=42\n",
    ")\n",
    "catboost_model.fit(X_train, Y_train, eval_set=(X_test, Y_test), use_best_model=True)\n",
    "\n",
    "Y_pred=xgbclassifier.predict(X_test)\n",
    "print(\"Accuracy: test\", accuracy_score(Y_test, Y_pred))\n",
    "print(\"\\nConfusion Matrix:test\\n\", confusion_matrix(Y_test, Y_pred))\n",
    "print(\"\\nClassification Report:test\\n\", classification_report(Y_test, Y_pred))\n",
    "\n",
    "Y_pred=xgbclassifier.predict(X_train)\n",
    "print(\"Accuracy:train\", accuracy_score(Y_train, Y_pred))\n",
    "print(\"\\nConfusion Matrix:train\\n\", confusion_matrix(Y_train, Y_pred))\n",
    "print(\"\\nClassification Report:train\\n\", classification_report(Y_train, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4501cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xgbclassifier, 'xgbclassifier_classifier_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(te, 'target_encoder.pkl')\n",
    "joblib.dump(pt, 'power_transformer_skewness_handler.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cat_encoders_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
